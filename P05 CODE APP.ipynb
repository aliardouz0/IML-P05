{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "130e2dc4-fa16-4f9e-aac9-5f1712344deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### charegemnt des differentes librarires necessaires\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "import timeit\n",
    "from sklearn.impute import KNNImputer\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import regex\n",
    "import re\n",
    "from bs4 import BeautifulSoup \n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f031cd5e-05f4-4f43-9b1c-b9b6f9a7714b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'tokenize' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-240c7ae303e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tfid_vcto.pk'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mtfid_vcto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'F_tags.pk'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'tokenize' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "# schema du cde de preprocessing\n",
    "#### DEFINE PREPROCESSING FUCTIONS \n",
    "##### BEAUTIFUL SOUP\n",
    "##### Tokenize\n",
    "##### DELETE STOP WORDS \n",
    "##### STEMMER\n",
    "##### untokenize\n",
    "# chargement des diferentes variables et modeles stcokés n local\n",
    "with open('sw.pk', 'rb') as file:\n",
    "    sw = pickle.load(file)\n",
    "\n",
    "with open('clf.pk', 'rb') as file:\n",
    "    clf = pickle.load(file)\n",
    "    \n",
    "with open('tfid_vcto.pk', 'rb') as file:\n",
    "    tfid_vcto = pickle.load(file)\n",
    "    \n",
    "with open('F_tags.pk', 'rb') as file:\n",
    "    F_tags = pickle.load(file)\n",
    "\n",
    "## definition des differentes fonctions à utiliser \n",
    "def tokenize(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(regex.sub(u'[^\\p{Latin}]', u' ', text))\n",
    "    return tokens\n",
    "\n",
    "def apply_BSoup(body):       \n",
    "\n",
    "    souped_body = []\n",
    "\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    text = soup.get_text() \n",
    "    #souped_body.append(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def delete_sw(body):\n",
    "    \n",
    "    filtered_body=[]\n",
    "    x = tokenize(body)\n",
    "\n",
    "    filtered_words = [word for word in x if word not in list(sw)]\n",
    "    filtered_body.append(filtered_words)\n",
    "    \n",
    "    return filtered_body\n",
    "\n",
    "def SB_stemmer(body):\n",
    "    \n",
    "    snowball = SnowballStemmer(language='english')\n",
    "\n",
    "    stemmed_body=[]\n",
    "    x = tokenize(body)\n",
    "\n",
    "    filtered_words = [snowball.stem(word) for word in x if word not in list(sw)]\n",
    "    stemmed_body.append(filtered_words)\n",
    "    \n",
    "    return(filtered_words)\n",
    "\n",
    "def untokenize(body):\n",
    "    untokenized_body = []\n",
    "    untokenized_body.append(TreebankWordDetokenizer().detokenize(body))\n",
    "    \n",
    "    return untokenized_body\n",
    "\n",
    "def preprocessing_text(text):\n",
    "    output = untokenize(SB_stemmer(apply_BSoup(text)))\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58961e4e-908a-4359-b074-fb6c351a7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_test = []\n",
    "body_test =\"<p>I'm writing an AJAX app, but as the user moves through the app, I'd like the URL in the address bar to update despite the lack of page reloads. Basically, I'd like for them to be able to bookmark at any point and thereby return to the current state. </p>\\n\\n<p>How are people handling maintaining RESTfulness in AJAX apps? </p>\\n\"\n",
    "var_test.append(body_test)\n",
    "body_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cb98b9-848b-435f-bf12-7996e6df824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_text(body_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d12095-aaea-4048-8037-3a140455a49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aeba5e7f-8e56-4997-93fc-85fc978fb854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 22 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tfidf_2.fit_transform(preprocessing_text(body_test))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8bf503f8-5cd6-431b-b1a4-20fbb0cb9e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>work</th>\n",
       "      <th>class</th>\n",
       "      <th>id</th>\n",
       "      <th>com</th>\n",
       "      <th>string</th>\n",
       "      <th>user</th>\n",
       "      <th>tri</th>\n",
       "      <th>name</th>\n",
       "      <th>net</th>\n",
       "      <th>...</th>\n",
       "      <th>durat</th>\n",
       "      <th>transit</th>\n",
       "      <th>school</th>\n",
       "      <th>pthread</th>\n",
       "      <th>complain</th>\n",
       "      <th>zend</th>\n",
       "      <th>asi</th>\n",
       "      <th>revis</th>\n",
       "      <th>typenam</th>\n",
       "      <th>beyond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     c  work  class   id  com  string      user  tri  name  net  ...  durat  \\\n",
       "0  0.0   0.0    0.0  0.0  0.0     0.0  0.174078  0.0   0.0  0.0  ...    0.0   \n",
       "\n",
       "   transit  school  pthread  complain  zend  asi  revis  typenam  beyond  \n",
       "0      0.0     0.0      0.0       0.0   0.0  0.0    0.0      0.0     0.0  \n",
       "\n",
       "[1 rows x 2000 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = pd.DataFrame(data = X.toarray(), columns=tfidf_2.get_feature_names())\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a2b64-6d0d-451c-9e4c-17a844a73f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0ad90fad-37b6-4ecd-ad3b-da786dc2652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(clf.predict(tf_idf), columns = F_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "452e4eae-fc12-4276-b02b-3161104106d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ajax\n"
     ]
    }
   ],
   "source": [
    "for col in prediction.columns:\n",
    "    if prediction[col][0] == 1:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944b81d1-154a-4c31-9dd0-457d6531368d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ec3477-48e0-465e-981a-c7f1a6b40b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
